{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def calculate_thresholds(data):\n",
        "    mean = data[\"amount\"].mean()\n",
        "    std_dev = data[\"amount\"].std()\n",
        "    q1 = data[\"amount\"].quantile(0.25)\n",
        "    q3 = data[\"amount\"].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    return {\n",
        "        \"mean\": mean,\n",
        "        \"std_dev\": std_dev,\n",
        "        \"z_score_threshold\": mean + 3 * std_dev,  # 3 standard deviations above the mean\n",
        "        \"iqr_upper_threshold\": q3 + 1.5 * iqr,   # 1.5 IQRs above the third quartile\n",
        "    }\n",
        "\n",
        "def calculate_mean_frequency(daily_category_freq):\n",
        "    mean_freq = daily_category_freq.groupby(\"category\").mean()\n",
        "    return mean_freq\n",
        "\n",
        "def is_zscore_outlier(transaction, category_data):\n",
        "    return transaction[\"amount\"] > category_data[\"z_score_threshold\"]\n",
        "\n",
        "def is_high_amount_outlier(transaction, category_data):\n",
        "    return transaction[\"amount\"] > 2 * category_data[\"mean\"]  # Adjust multiplier as needed\n",
        "\n",
        "def is_iqr_outlier(transaction, category_data):\n",
        "    return transaction[\"amount\"] > category_data[\"iqr_upper_threshold\"]\n",
        "\n",
        "def get_historical_transactions(transactions, category, date, window=7):\n",
        "    \"\"\"\n",
        "    This function retrieves historical transactions for a given category within a specified window.\n",
        "\n",
        "    Args:\n",
        "        transactions (pd.DataFrame): DataFrame containing transaction data.\n",
        "        category (str): Transaction category to retrieve historical data for.\n",
        "        date (datetime): Date of the transaction to look back from.\n",
        "        window (int, optional): Window size in days to look back (default: 7).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing historical transactions for the category.\n",
        "    \"\"\"\n",
        "    start_date = date - timedelta(days=window)\n",
        "    return transactions.loc[(transactions[\"category\"] == category) & (transactions[\"date\"] >= start_date) & (transactions[\"date\"] < date)]\n",
        "\n",
        "def is_time_series_outlier(transaction, transactions, window_size=7):\n",
        "    \"\"\"\n",
        "    This function checks for transaction anomalies based on deviation from the moving average within a category.\n",
        "\n",
        "    Args:\n",
        "        transaction (dict): Transaction data with category and amount.\n",
        "        transactions (pd.DataFrame): DataFrame containing all transaction data.\n",
        "        window_size (int): Rolling window size for moving average calculation (default=7).\n",
        "\n",
        "    Returns:\n",
        "        bool: True if transaction is an anomaly, False otherwise.\n",
        "    \"\"\"\n",
        "    category = transaction[\"category\"]\n",
        "    date = transaction[\"date\"]\n",
        "\n",
        "    # Access historical transactions for the category\n",
        "    category_history = get_historical_transactions(transactions, category, date, window_size)\n",
        "\n",
        "    # Calculate moving average and standard deviation for the window\n",
        "    if not category_history.empty:\n",
        "        rolling_average = category_history[\"amount\"].mean()\n",
        "        rolling_std_dev = category_history[\"amount\"].std()\n",
        "\n",
        "        # Check if transaction amount deviates significantly from the moving average\n",
        "        threshold = rolling_average + 2 * rolling_std_dev  # Adjust threshold as needed\n",
        "        return transaction[\"amount\"] > threshold\n",
        "    return False\n",
        "\n",
        "def detect_anomalies(data_file):\n",
        "    \"\"\"\n",
        "    This function reads transaction data, detects anomalies based on amount, frequency,\n",
        "    and irregular patterns (implement later), and generates a report.\n",
        "\n",
        "    Args:\n",
        "        data_file (str): Path to the CSV file containing transaction data.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    transactions = pd.read_csv(data_file)\n",
        "\n",
        "    # Convert date column to datetime format\n",
        "    transactions[\"date\"] = pd.to_datetime(transactions[\"date\"])\n",
        "\n",
        "    # Group transactions by category and calculate statistics\n",
        "    category_stats = transactions.groupby(\"category\").apply(calculate_thresholds).to_dict()\n",
        "\n",
        "    # Calculate daily transaction frequency by category\n",
        "    daily_category_freq = transactions.groupby([\"date\", \"category\"]).size().to_frame(name=\"count\").reset_index()\n",
        "    mean_category_freq = calculate_mean_frequency(daily_category_freq)\n",
        "\n",
        "    # Detect anomalies and create report data\n",
        "    anomaly_report = []\n",
        "    for index, row in transactions.iterrows():\n",
        "        category_data = category_stats[row[\"category\"]]\n",
        "        daily_freq = daily_category_freq[(daily_category_freq[\"date\"] == row[\"date\"]) & (daily_category_freq[\"category\"] == row[\"category\"])][\"count\"].values[0]\n",
        "        mean_freq = mean_category_freq.loc[row[\"category\"]][\"count\"]\n",
        "\n",
        "        if daily_freq > mean_freq:\n",
        "            anomaly_report.append(\n",
        "                {\n",
        "                    \"transaction_id\": row[\"transaction_id\"],\n",
        "                    \"date\": row[\"date\"].strftime(\"%Y-%m-%d\"),\n",
        "                    \"category\": row[\"category\"],\n",
        "                    \"amount\": row[\"amount\"],\n",
        "                    \"reason_for_anomaly\": \"High frequency anomaly\",\n",
        "                    \"category_anomaly\": True,\n",
        "                }\n",
        "            )\n",
        "        elif is_zscore_outlier(row, category_data):\n",
        "            anomaly_report.append(\n",
        "                {\n",
        "                    \"transaction_id\": row[\"transaction_id\"],\n",
        "                    \"date\": row[\"date\"].strftime(\"%Y-%m-%d\"),\n",
        "                    \"category\": row[\"category\"],\n",
        "                    \"amount\": row[\"amount\"],\n",
        "                    \"reason_for_anomaly\": \"Z-score anomaly\",\n",
        "                    \"category_anomaly\": False,\n",
        "                }\n",
        "            )\n",
        "        elif is_high_amount_outlier(row, category_data):\n",
        "            anomaly_report.append(\n",
        "                {\n",
        "                    \"transaction_id\": row[\"transaction_id\"],\n",
        "                    \"date\": row[\"date\"].strftime(\"%Y-%m-%d\"),\n",
        "                    \"category\": row[\"category\"],\n",
        "                    \"amount\": row[\"amount\"],\n",
        "                    \"reason_for_anomaly\": \"Unusually high transaction amount\",\n",
        "                    \"category_anomaly\": False,\n",
        "                }\n",
        "            )\n",
        "        elif is_iqr_outlier(row, category_data):\n",
        "            anomaly_report.append(\n",
        "                {\n",
        "                    \"transaction_id\": row[\"transaction_id\"],\n",
        "                    \"date\": row[\"date\"].strftime(\"%Y-%m-%d\"),\n",
        "                    \"category\": row[\"category\"],\n",
        "                    \"amount\": row[\"amount\"],\n",
        "                    \"reason_for_anomaly\": \"IQR anomaly\",\n",
        "                    \"category_anomaly\": False,\n",
        "                }\n",
        "            )\n",
        "        elif is_time_series_outlier(row, transactions):\n",
        "            anomaly_report.append(\n",
        "                {\n",
        "                    \"transaction_id\": row[\"transaction_id\"],\n",
        "                    \"date\": row[\"date\"].strftime(\"%Y-%m-%d\"),\n",
        "                    \"category\": row[\"category\"],\n",
        "                    \"amount\": row[\"amount\"],\n",
        "                    \"reason_for_anomaly\": \"Time series anomaly\",\n",
        "                    \"category_anomaly\": False,\n",
        "                }\n",
        "            )\n",
        "        else:\n",
        "            # No anomaly detected for this transaction\n",
        "            pass\n",
        "\n",
        "    # Print anomaly report\n",
        "    if anomaly_report:\n",
        "        print(\"Anomaly Report:\")\n",
        "        for anomaly in anomaly_report:\n",
        "            print(anomaly)\n",
        "    else:\n",
        "        print(\"No anomalies detected.\")\n",
        "\n",
        "# Assuming the CSV file path is correct\n",
        "detect_anomalies('/content/dummy_transactions.csv')\n"
      ],
      "metadata": {
        "id": "AdyPxOqws6Ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s2murbU0s6FS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}